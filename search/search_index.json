{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"contact_us/","text":"Contact US \u00b6 Need any more support feel free to contact us!! Contact No. \u00b6 0495-228 5600 Email \u00b6 ccmsadmin@nitc.ac.in Address \u00b6 Centre for Computaional Modelling & Simulation, National Institute of Technology Calicut, NIT Campus P.O 673 601, Kozhikode, India","title":"Contact Us"},{"location":"contact_us/#contact-us","text":"Need any more support feel free to contact us!!","title":"Contact US"},{"location":"contact_us/#contact-no","text":"0495-228 5600","title":"Contact No."},{"location":"contact_us/#email","text":"ccmsadmin@nitc.ac.in","title":"Email"},{"location":"contact_us/#address","text":"Centre for Computaional Modelling & Simulation, National Institute of Technology Calicut, NIT Campus P.O 673 601, Kozhikode, India","title":"Address"},{"location":"envmod/","text":"Access to installed software using Environment Modules \u00b6 Applications, software, compilers, tools, communications libraries and math libraries of the cluster system are being keep up-to-date. Madhava HPC use the Environment Modules to dynamically set up environments for different applications. Module commands set, change, or delete environment variables that are needed for a particular application. The \u2018module load\u2018 command will set PATH, LD_LIBRARY_PATH and other environment variables such that user may choose a desired version of applications or libraries more easily. More details can be found here. Finding out which modules (and hence which compilers, libraries and software) are available on the system is performed using the module avail command: Module manipulation commands \u00b6 Command Description module avail or ml avail Show the available modules ready for loading module keyword [word1] [word2] Search for available modules matching the keyword(s) module spider word Show the details of any modules matching the keyword(s) module whatis [mod] or module help [mod] Show description of a module module load [mod] or ml [mod] Load the environment for the default version of the modulefile module load [modA] [modB] [modC] Load the environment for the default version of modules named modA, modB and modC in corresponding order module load [mod]/[version] Load the environment for the specified version of module module unload [mod] or module unload [modA] [modB] Roll back configuration performed by the modulefile(s) module swap [modA] [modB] Unload modulefile A and load modulefile B module list or ml List any currently loaded module(s) module purge Unload all modules currently loaded Info As new versions of software get installed and others are deprecated, the default module version can change over time. It is best practice to note the specific module versions you are using for a project and load those explicitly, e.g. module load python3/3.8.9 not module load python . This makes your work more reproducible and less likely to change unexpectedly in the future. Module interoperability and dependency \u00b6 When one module is in conflict with another (e.g different MPI libraries), the conflicting module may have to be unloaded before a desired one is loaded. Besides, some modules may depend on one another and hence they may be loaded/unloaded as a consequence of a subsequent module command in a dynamic fashion.","title":"Environment Modules"},{"location":"envmod/#access-to-installed-software-using-environment-modules","text":"Applications, software, compilers, tools, communications libraries and math libraries of the cluster system are being keep up-to-date. Madhava HPC use the Environment Modules to dynamically set up environments for different applications. Module commands set, change, or delete environment variables that are needed for a particular application. The \u2018module load\u2018 command will set PATH, LD_LIBRARY_PATH and other environment variables such that user may choose a desired version of applications or libraries more easily. More details can be found here. Finding out which modules (and hence which compilers, libraries and software) are available on the system is performed using the module avail command:","title":"Access to installed software using Environment Modules"},{"location":"envmod/#module-manipulation-commands","text":"Command Description module avail or ml avail Show the available modules ready for loading module keyword [word1] [word2] Search for available modules matching the keyword(s) module spider word Show the details of any modules matching the keyword(s) module whatis [mod] or module help [mod] Show description of a module module load [mod] or ml [mod] Load the environment for the default version of the modulefile module load [modA] [modB] [modC] Load the environment for the default version of modules named modA, modB and modC in corresponding order module load [mod]/[version] Load the environment for the specified version of module module unload [mod] or module unload [modA] [modB] Roll back configuration performed by the modulefile(s) module swap [modA] [modB] Unload modulefile A and load modulefile B module list or ml List any currently loaded module(s) module purge Unload all modules currently loaded Info As new versions of software get installed and others are deprecated, the default module version can change over time. It is best practice to note the specific module versions you are using for a project and load those explicitly, e.g. module load python3/3.8.9 not module load python . This makes your work more reproducible and less likely to change unexpectedly in the future.","title":"Module manipulation commands"},{"location":"envmod/#module-interoperability-and-dependency","text":"When one module is in conflict with another (e.g different MPI libraries), the conflicting module may have to be unloaded before a desired one is loaded. Besides, some modules may depend on one another and hence they may be loaded/unloaded as a consequence of a subsequent module command in a dynamic fashion.","title":"Module interoperability and dependency"},{"location":"getting-started/","text":"Introduction \u00b6 Centre for Computational Modelling and Simulation (CCMS) aims to promote and support computational modelling as a mainstream research activity amongst the faculty and researchers of NIT Calicut. A High Performance Computing (HPC) Cluster and NVIDIA DGX Station purchased under HEFA are the major computing facility under this centre. The facility consists of 31 CPU nodes and 2 GPU nodes. The NVIDIA DGX Station has four V100 GPU accelerators. The facility is mainly for developing and running parallel codes for research purposes. The HPC system installed has been ranked as the 38th in the list of top 100 computing machines in India, in January 2021, a list maintained by CDAC, Bangalore click here . System Configuration \u00b6 Wanted to know about system configuration \ud83d\ude00? Check the it here Get an Account for You \u00b6 Centre for computational Modelling and Simulation (CCMS) comprises of a High Performance Computing cluster and a DGX Station that are available to both faculty and students. Inorder to get an account you may download the application and submit filled application to the mail id : ccmsadmin@nitc.ac.in or through hardcopy You will be notified once your account is approved. For NITC students, recommendation from the guide/ faculty is mandatory. A short proposal describing the computing to be carried out, justification for the use of HPC facility and expected outcome (1 page only) is to be attached with the submitted form. System Access \u00b6 The cluster can be accessed through Master node, which allows users to login, to submit jobs, transfer data and to compile source code. (If your compilation takes more than a few minutes, you should submit the compilation job into the queue to be run on the cluster.) By default, a user will have access to home directory (/gpfs-home/) This directory is available on the login node as well as the other nodes on the cluster. And the /gpfs-scratch/ directory may be used for temporary data storage, generally used to store data required for running jobs. Any data stored in /gpfs-scratch will be deleted after 30 days. Remote Access \u00b6 Using ssh in Windows \u00b6 Windows systems do not have any built-in support for using SSH, so you will have to download a software package to use SSH. PuTTY is the most popular open source (ie free) SSH client for Windows. To install it, visit the download site, and download the Installer package. Once installed, find the PuTTy application shortcut in your Start Menu, desktop. On clicking the PuTTy icon The PuTTy Configuration dialog should appear: Locate the Host Name input box in the PuTTy Configuration screen. Enter the server name you wish to connect to (e.g. [username]@[hpcipaddress]), and click Open. Enter your password when prompted, and press Enter. You are now connected! Using ssh in Mac or Linux \u00b6 Both Mac and Linux systems provide a built-in SSH client, so there is no need to install an additional package. Simply locate and run the Terminal app. Once in the terminal, you can connect to an SSH server by typing the following command: ```console // to access from your pc user@my-pc:~$ ssh username@hostid // if a remote GUI section is required user@my-pc:~$ ssh username@hostid -X ``` Note Your user name and the hostid will be recieved through mail. Please check that. and replace username & hostid with appropriate value If you want to access the clusters from outside NITC's network, you must use the NITC VPN. How to change the user password? Use the \"passwd\" command to change the password for the user from the login node. Transferring files between local machine and HPC cluster \u00b6 Users need to have the data and application related to their project/research work on Madhava HPC Cluster To store the data special directories have been made available to the users with name \u201cscratch and home\u201d the path to this directory is \u201c/gpfs-scratch\u201d and \u201c/gpfs-home\u201d. Whereas these directories are common to all the users, a user will get his own directory with their username in /gpfs-scratch/ as well as /home-home/ directories where they can store their data. However, there is limit to the storage provided to the users, the limits have been defined according to quota over these directories, all users will be allotted same quota by default. When a user wishes to transfer data from their local system (laptop/desktop) to HPC system, they can use various methods and tools A user using the \u2018Windows\u2019 operating system will get methods and tools that are native to Microsoft Windows and tools that could be installed on your Microsoft Windows machine.Linux operating system users do not require any tool. They can just use \u201cscp\u201d command on their terminal, as mentioned below. Users are advised to keep a copy of their data with themselves, once the project/research work is completed by transferring the data in from Madhava HPC Cluster to their local system (laptop/desktop). The command shown below can be used for effecting file transfers (In all the tools): scp \u2013r [path to the local data directory] [your username]@[IP of Madhava HPC:[path to directory on HPC where to save the data] for example: scp \u2013r /dir/dir/file sajil@:/gpfs-home/sajil Same Command could be used to transfer data from HPC system to your local system (laptop/desktop). scp \u2013r [your username]@[IP of Madhava HPC:[path todirectory on HPC where to save the data] [path to the local data directory] for example: scp \u2013r sajil@[cluster IP/Name]:/gpfs-home/sajil/file /dir/dir/file Addressing Basic Security Concerns \u00b6 Your account on Madhava HPC Cluster is \u2018private to you\u2019. You are responsible for any actions emanating from your account. It is suggested that you should never share the password to anyone. Please note that, by default, a new account created on Madhava HPC Cluster is readable by everyone on the system. The following simple commands will make your account adequately safe. Command Discription chmod 700 [directory name] will ensure that only yourself can read, write and execute files in your directory chmod 750 [directory name] will enable yourself and the members of your group to read and execute files in your directory chmod 775 [directory name] will enable yourself, your group members and everyone else to read and execute files in your directory chmod 777 [directory name] will enable EVERY ONE on the system to read, write and execute files in your directory. This is a sort of \u2018free for all\u2019 situation. This should be used very judiciously","title":"Getting started"},{"location":"getting-started/#introduction","text":"Centre for Computational Modelling and Simulation (CCMS) aims to promote and support computational modelling as a mainstream research activity amongst the faculty and researchers of NIT Calicut. A High Performance Computing (HPC) Cluster and NVIDIA DGX Station purchased under HEFA are the major computing facility under this centre. The facility consists of 31 CPU nodes and 2 GPU nodes. The NVIDIA DGX Station has four V100 GPU accelerators. The facility is mainly for developing and running parallel codes for research purposes. The HPC system installed has been ranked as the 38th in the list of top 100 computing machines in India, in January 2021, a list maintained by CDAC, Bangalore click here .","title":"Introduction"},{"location":"getting-started/#system-configuration","text":"Wanted to know about system configuration \ud83d\ude00? Check the it here","title":"System Configuration"},{"location":"getting-started/#get-an-account-for-you","text":"Centre for computational Modelling and Simulation (CCMS) comprises of a High Performance Computing cluster and a DGX Station that are available to both faculty and students. Inorder to get an account you may download the application and submit filled application to the mail id : ccmsadmin@nitc.ac.in or through hardcopy You will be notified once your account is approved. For NITC students, recommendation from the guide/ faculty is mandatory. A short proposal describing the computing to be carried out, justification for the use of HPC facility and expected outcome (1 page only) is to be attached with the submitted form.","title":"Get an Account for You"},{"location":"getting-started/#system-access","text":"The cluster can be accessed through Master node, which allows users to login, to submit jobs, transfer data and to compile source code. (If your compilation takes more than a few minutes, you should submit the compilation job into the queue to be run on the cluster.) By default, a user will have access to home directory (/gpfs-home/) This directory is available on the login node as well as the other nodes on the cluster. And the /gpfs-scratch/ directory may be used for temporary data storage, generally used to store data required for running jobs. Any data stored in /gpfs-scratch will be deleted after 30 days.","title":"System Access"},{"location":"getting-started/#remote-access","text":"","title":"Remote Access"},{"location":"getting-started/#using-ssh-in-windows","text":"Windows systems do not have any built-in support for using SSH, so you will have to download a software package to use SSH. PuTTY is the most popular open source (ie free) SSH client for Windows. To install it, visit the download site, and download the Installer package. Once installed, find the PuTTy application shortcut in your Start Menu, desktop. On clicking the PuTTy icon The PuTTy Configuration dialog should appear: Locate the Host Name input box in the PuTTy Configuration screen. Enter the server name you wish to connect to (e.g. [username]@[hpcipaddress]), and click Open. Enter your password when prompted, and press Enter. You are now connected!","title":"Using ssh in Windows"},{"location":"getting-started/#using-ssh-in-mac-or-linux","text":"Both Mac and Linux systems provide a built-in SSH client, so there is no need to install an additional package. Simply locate and run the Terminal app. Once in the terminal, you can connect to an SSH server by typing the following command: ```console // to access from your pc user@my-pc:~$ ssh username@hostid // if a remote GUI section is required user@my-pc:~$ ssh username@hostid -X ``` Note Your user name and the hostid will be recieved through mail. Please check that. and replace username & hostid with appropriate value If you want to access the clusters from outside NITC's network, you must use the NITC VPN. How to change the user password? Use the \"passwd\" command to change the password for the user from the login node.","title":"Using ssh in Mac or Linux"},{"location":"getting-started/#transferring-files-between-local-machine-and-hpc-cluster","text":"Users need to have the data and application related to their project/research work on Madhava HPC Cluster To store the data special directories have been made available to the users with name \u201cscratch and home\u201d the path to this directory is \u201c/gpfs-scratch\u201d and \u201c/gpfs-home\u201d. Whereas these directories are common to all the users, a user will get his own directory with their username in /gpfs-scratch/ as well as /home-home/ directories where they can store their data. However, there is limit to the storage provided to the users, the limits have been defined according to quota over these directories, all users will be allotted same quota by default. When a user wishes to transfer data from their local system (laptop/desktop) to HPC system, they can use various methods and tools A user using the \u2018Windows\u2019 operating system will get methods and tools that are native to Microsoft Windows and tools that could be installed on your Microsoft Windows machine.Linux operating system users do not require any tool. They can just use \u201cscp\u201d command on their terminal, as mentioned below. Users are advised to keep a copy of their data with themselves, once the project/research work is completed by transferring the data in from Madhava HPC Cluster to their local system (laptop/desktop). The command shown below can be used for effecting file transfers (In all the tools): scp \u2013r [path to the local data directory] [your username]@[IP of Madhava HPC:[path to directory on HPC where to save the data] for example: scp \u2013r /dir/dir/file sajil@:/gpfs-home/sajil Same Command could be used to transfer data from HPC system to your local system (laptop/desktop). scp \u2013r [your username]@[IP of Madhava HPC:[path todirectory on HPC where to save the data] [path to the local data directory] for example: scp \u2013r sajil@[cluster IP/Name]:/gpfs-home/sajil/file /dir/dir/file","title":"Transferring files between local machine and HPC cluster"},{"location":"getting-started/#addressing-basic-security-concerns","text":"Your account on Madhava HPC Cluster is \u2018private to you\u2019. You are responsible for any actions emanating from your account. It is suggested that you should never share the password to anyone. Please note that, by default, a new account created on Madhava HPC Cluster is readable by everyone on the system. The following simple commands will make your account adequately safe. Command Discription chmod 700 [directory name] will ensure that only yourself can read, write and execute files in your directory chmod 750 [directory name] will enable yourself and the members of your group to read and execute files in your directory chmod 775 [directory name] will enable yourself, your group members and everyone else to read and execute files in your directory chmod 777 [directory name] will enable EVERY ONE on the system to read, write and execute files in your directory. This is a sort of \u2018free for all\u2019 situation. This should be used very judiciously","title":"Addressing Basic Security Concerns"},{"location":"job-array/","text":"SLURM Job Array \u00b6 Job arrays offer a mechanism for submitting and managing collections of similar but independent jobs quickly and easily. Job arrays are only supported for batch jobs and the array index values are specified using the \u2013array or -a option of the #SBATCH directive in a SLURM job command file. #SBATCH --array=s-e s: Start index (Minimum is 0) e: End index (Maximum is 1000) A job array can also be specified at the command line with $ sbatch --array=s-e job.cmd Examples \u00b6 A job array will be created with a number of independent jobs corresponding to the defined array with task id, 1,2,3 \u2026 20. $ sbatch --array=1-20 job.cmd A comma-separated list of task numbers rather a range can be provided. $ sbatch --array=1,2,4,8 job.cmd A job array with array tasks numbered 1, 3, 6 and 9. #SBATCH --array=1-9:3 Naming output and error files \u00b6 SLURM uses the %A and %a replacement strings for the master job id and task id, respectively. Example: \u00b6 #SBATCH --output=myjob.%A_%a.out #SBATCH --error=myjob.%A_%a.err Limiting the number of active job array tasks \u00b6 To limit a job array by having only a certain number of tasks active at a time, %N suffix may be used where N is the number of active tasks. An example below will submit a 50 task job array with only 10 tasks active at a time. #SBATCH -a 1-50%10 If you want to change the number of concurrent tasks of an active job after submission, you may run: $ scontrol update ArrayTaskThrottle= JobId= eg $ scontrol update ArrayTaskThrottle=20 JobId=2021 Example job command file with job array #!/bin/bash #SBATCH --job-name=array_job #SBATCH --output=array_job_%A_%a.out #SBATCH --error=array_job_%A_%a.err #SBATCH --array=1-6 #SBATCH --time=01:00:00 #SBATCH --partition=shortq #SBATCH --ntasks=1 #SBATCH --mem=6G echo \"SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID ml gatk gatk HaplotypeCaller -I sample1.bam -L $SLURM_ARRAY_TASK_ID ... An environment variable, $SLURM_ARRAY_TASK_ID is assigned by SLURM to each array task, which can be referenced inside a job script to handle program parameters, input and output. Alternatively, you may run the following if the you have a file \u201cindividual.txt\u201d where each line contains an item to be processed. individual_list=($(<individual.txt)) individual=${individual_list[${SLURM_ARRAY_TASK_ID}]} gatk haplotypecaller -I ${individual} ... Deleting job arrays and tasks \u00b6 To delete all of the tasks of an array job, use scancel with the job ID: $ scancel 2021 To delete a single task, add the task ID: $ scancel 2021_7","title":"Slurm Job Arrays"},{"location":"job-array/#slurm-job-array","text":"Job arrays offer a mechanism for submitting and managing collections of similar but independent jobs quickly and easily. Job arrays are only supported for batch jobs and the array index values are specified using the \u2013array or -a option of the #SBATCH directive in a SLURM job command file. #SBATCH --array=s-e s: Start index (Minimum is 0) e: End index (Maximum is 1000) A job array can also be specified at the command line with $ sbatch --array=s-e job.cmd","title":"SLURM Job Array"},{"location":"job-array/#examples","text":"A job array will be created with a number of independent jobs corresponding to the defined array with task id, 1,2,3 \u2026 20. $ sbatch --array=1-20 job.cmd A comma-separated list of task numbers rather a range can be provided. $ sbatch --array=1,2,4,8 job.cmd A job array with array tasks numbered 1, 3, 6 and 9. #SBATCH --array=1-9:3","title":"Examples"},{"location":"job-array/#naming-output-and-error-files","text":"SLURM uses the %A and %a replacement strings for the master job id and task id, respectively.","title":"Naming output and error files"},{"location":"job-array/#example","text":"#SBATCH --output=myjob.%A_%a.out #SBATCH --error=myjob.%A_%a.err","title":"Example:"},{"location":"job-array/#limiting-the-number-of-active-job-array-tasks","text":"To limit a job array by having only a certain number of tasks active at a time, %N suffix may be used where N is the number of active tasks. An example below will submit a 50 task job array with only 10 tasks active at a time. #SBATCH -a 1-50%10 If you want to change the number of concurrent tasks of an active job after submission, you may run: $ scontrol update ArrayTaskThrottle= JobId= eg $ scontrol update ArrayTaskThrottle=20 JobId=2021 Example job command file with job array #!/bin/bash #SBATCH --job-name=array_job #SBATCH --output=array_job_%A_%a.out #SBATCH --error=array_job_%A_%a.err #SBATCH --array=1-6 #SBATCH --time=01:00:00 #SBATCH --partition=shortq #SBATCH --ntasks=1 #SBATCH --mem=6G echo \"SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID ml gatk gatk HaplotypeCaller -I sample1.bam -L $SLURM_ARRAY_TASK_ID ... An environment variable, $SLURM_ARRAY_TASK_ID is assigned by SLURM to each array task, which can be referenced inside a job script to handle program parameters, input and output. Alternatively, you may run the following if the you have a file \u201cindividual.txt\u201d where each line contains an item to be processed. individual_list=($(<individual.txt)) individual=${individual_list[${SLURM_ARRAY_TASK_ID}]} gatk haplotypecaller -I ${individual} ...","title":"Limiting the number of active job array tasks"},{"location":"job-array/#deleting-job-arrays-and-tasks","text":"To delete all of the tasks of an array job, use scancel with the job ID: $ scancel 2021 To delete a single task, add the task ID: $ scancel 2021_7","title":"Deleting job arrays and tasks"},{"location":"job-depend/","text":"SLURM Job Dependencies \u00b6 You may submit jobs that runs depending on status of the previously submitted jobs or schedule a bunch of jobs to run one after the other. Once you submit a job, using that job ID, you can submit dependency jobs. You need to extract the job id \u201c12345\u201d from the output of the \u201csbatch\u201d command $ sbatch job.cmd Submitted batch job 12345 By adding the \u201c--parsable\u201d option to \u201csbatch command\u201d, only the job ID would be returned and its value can be stored in a shell variable for later use. $ jobID=$(sbatch --parsable job.cmd) $ echo ${jobID} 12345 Next, you can submit a job that only runs after successful completion of the first job as follows where we set the \u201cafterok\u201d as the dependency type. $ sbatch --dependency=afterok:${jobID} second_job.cmd The format here is $ sbatch --dependency=type:job_id jobfile If the job requires more than one job to be completed before it is executed, you can supply all the jobids using , separator $ sbatch --dependency=type:job_id,job_id,job_id jobfile You can also set the job to run if any one of the job ids completes successfully using a ? separator $ sbatch --dependency=type:job_id?job_id?job_id jobfile The other dependencies that can be used for are as follows: Type Description after This job can begin execution after the specified jobs have begun execution afterany This job can begin execution after the specified jobs have terminated. aftercorr A task of this job array can begin execution after the corresponding task ID in the specified job has completed successfully afternotok This job can begin execution after the specified jobs have terminated in some failed state afterok This job can begin execution after the specified jobs have successfully executed singleton This job can begin execution after any previously launched jobs sharing the same job name and user have terminated","title":"Slurm Job Dependencies"},{"location":"job-depend/#slurm-job-dependencies","text":"You may submit jobs that runs depending on status of the previously submitted jobs or schedule a bunch of jobs to run one after the other. Once you submit a job, using that job ID, you can submit dependency jobs. You need to extract the job id \u201c12345\u201d from the output of the \u201csbatch\u201d command $ sbatch job.cmd Submitted batch job 12345 By adding the \u201c--parsable\u201d option to \u201csbatch command\u201d, only the job ID would be returned and its value can be stored in a shell variable for later use. $ jobID=$(sbatch --parsable job.cmd) $ echo ${jobID} 12345 Next, you can submit a job that only runs after successful completion of the first job as follows where we set the \u201cafterok\u201d as the dependency type. $ sbatch --dependency=afterok:${jobID} second_job.cmd The format here is $ sbatch --dependency=type:job_id jobfile If the job requires more than one job to be completed before it is executed, you can supply all the jobids using , separator $ sbatch --dependency=type:job_id,job_id,job_id jobfile You can also set the job to run if any one of the job ids completes successfully using a ? separator $ sbatch --dependency=type:job_id?job_id?job_id jobfile The other dependencies that can be used for are as follows: Type Description after This job can begin execution after the specified jobs have begun execution afterany This job can begin execution after the specified jobs have terminated. aftercorr A task of this job array can begin execution after the corresponding task ID in the specified job has completed successfully afternotok This job can begin execution after the specified jobs have terminated in some failed state afterok This job can begin execution after the specified jobs have successfully executed singleton This job can begin execution after any previously launched jobs sharing the same job name and user have terminated","title":"SLURM Job Dependencies"},{"location":"job-schedule-manage/","text":"Job Scheduling and managing \u00b6 Schedule a Job \u00b6 On our cluster, you control your jobs using a job scheduling system called Slurm that allocates and manages compute resources for you. You can submit your jobs in one of two ways. For testing and small jobs you may want to run a job interactively. This way you can directly interact with the compute node(s) in real time. The other way, which is the preferred way for multiple jobs or long-running jobs, involves writing your job commands in a script and submitting that to the job scheduler. Please see our Slurm documentation for more details. Running Interactive Jobs \u00b6 In general, the jobs can be run in an interactive manner or in batch mode. You can run an interactive job as follows: The following command asks for a single core in testq for one hour with a default amount of memory. srun --nodes=1 --ntasks-per-node=1 --time=01:00:00 \u2013partition=testq \u2013job-name= job-name --pty /usr/bin/bash The command prompt will appear as soon as the job starts. This is how it looks once the interactive job starts: image Exit the bash shell to end the job. If you exceed the time or memory limits the job will also abort. Please note that Madhava HPC Cluster is NOT meant for executing interactive jobs. However, for the purpose of quickly ascertaining successful run of a job before submitting a large job in batch (with large iteration counts), this can be used. This can even be used for running small jobs. The point to be kept in mind is that, since others too would be using this node, it is prudent not to inconvenience them by running large jobs. Submit the Job \u00b6 To Submitting a simple standalone job , This is a simple submit script which is to be submitted sbatch job-script-name A sample Slurm job script #!/bin/sh #SBATCH --nodes 1 // specifies number of nodes #SBATCH --ntasks-per-node=40 // specifies core per node #SBATCH --time=06:50:20 // specifies maximum duration of run #SBATCH --job-name=lammps // specifies job name #SBATCH --output=job_output.txt //specifies output file name #SBATCH --partition=shortq // specifies queue name #SBATCH --ntasks=10 //specifies total no of cores required ########################################################## echo \u201cJob Submitted\u201d #load required modules module load ... #------------- run your commands here\u2014-----------------# mpirun -n $SLURM_NTASKS ... echo \u201cJob finished successfully\u201d Managing Jobs \u00b6 Madhava HPC Cluster extensively uses modules. The purpose of the module is to provide the production environment for a given application, outside of the application itself. This also specifies which version of the application is available for a given session. All applications and libraries are made available through module files. A User has to load the appropriate module from the available modules. module avail # This command lists all the available modules module load compilers/intel/parallel_studio_xe_2020.4.912 # This will load the intel compilers into your environment module unload compilers/intel/parallel_studio_xe_2020.4.912 # This will remove all environment setting related to intel compiler loaded previously module list #This will list currently loaded modules. List Partition \u00b6 sinfo displays information about nodes and partitions(queues). sinfo List jobs \u00b6 Monitoring jobs on SLURM can be done using the command squeue. squeue is used to view job and job step information for jobs managed by SLURM squeue Get job details \u00b6 scontrol can be used to report more detailed information about nodes, partitions, jobs, job steps, and configuration. scontrol show node - shows detailed information about compute nodes. scontrol show partition - shows detailed information about a specific partition scontrol show job - shows detailed information about a specific job or all jobs if no job id isgiven. scontrol update job - change attributes of submitted job. Suspend a job (root only): \u00b6 # scontrol suspend 135 # squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 135 shortq simple.s user1 S 0:13 1 compute01 Resume a job (root only): \u00b6 # scontrol resume 135 # squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 135 shortq simple.s user1 R 0:13 1 compute01 Kill a job. Users can kill their own jobs, root can kill any job. $ scancel 135 $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) Hold a job: \u00b6 $ scontrol hold 139 Release a job: $ scontrol release 139 More about Batch Jobs (SLURM) \u00b6 SLURM (Simple Linux Utility for Resource Management) is a workload manager that provides a framework for job queues, allocation of compute nodes, and the start and execution of jobs. It is important to note: Compilations are done on the login node. Only the execution is scheduled via SLURM on the compute/GPU nodes Upon Submission of a Job script, each job gets a unique Job Id. This can be obtained from the \u2018squeue\u2019 command. The Job Id is also appended to the output and error filenames. Parameters used in SLURM job Script \u00b6 The job flags are used with SBATCH command. The syntax for the SLURM directive in a script is \"#SBATCH \". Some of the flags are used with the srun and salloc commands. Resource Flag Syntax Description partition --partition=partition-name Partition is a queue for jobs. time --time=01:00:00 Time limit for the job. nodes --nodes=2 Number of compute nodes for for the job cpus/cores --ntasks-per-node=8 Corresponds to number of cores on the compute node job name --job-name=\"job-1\" Name of job output file --output=job-1.out Name of file for stdout. access --exclusive Exclusive access to computenodes resource --gres=gpu:2 Request use of GPUs on compute node Some useful SLURM commands. \u00b6 Sl No Purpose Command 1 To check the queue status squeue 2 To check the status/ availability of nodes sinfo 3 To cancel a job running scancel note: job id can be obtained by command squeue 4 To check the jobs of a particular user squeue -u 5 To list all running jobs of a user squeue -u -t RUNNING 6 To list all pending jobs of a user squeue -u -t PENDING 7 To cancel all the pending jobs for a user scancel -t PENDING -u username","title":"Job Scheduling and Managing"},{"location":"job-schedule-manage/#job-scheduling-and-managing","text":"","title":"Job Scheduling and managing"},{"location":"job-schedule-manage/#schedule-a-job","text":"On our cluster, you control your jobs using a job scheduling system called Slurm that allocates and manages compute resources for you. You can submit your jobs in one of two ways. For testing and small jobs you may want to run a job interactively. This way you can directly interact with the compute node(s) in real time. The other way, which is the preferred way for multiple jobs or long-running jobs, involves writing your job commands in a script and submitting that to the job scheduler. Please see our Slurm documentation for more details.","title":"Schedule a Job"},{"location":"job-schedule-manage/#running-interactive-jobs","text":"In general, the jobs can be run in an interactive manner or in batch mode. You can run an interactive job as follows: The following command asks for a single core in testq for one hour with a default amount of memory. srun --nodes=1 --ntasks-per-node=1 --time=01:00:00 \u2013partition=testq \u2013job-name= job-name --pty /usr/bin/bash The command prompt will appear as soon as the job starts. This is how it looks once the interactive job starts: image Exit the bash shell to end the job. If you exceed the time or memory limits the job will also abort. Please note that Madhava HPC Cluster is NOT meant for executing interactive jobs. However, for the purpose of quickly ascertaining successful run of a job before submitting a large job in batch (with large iteration counts), this can be used. This can even be used for running small jobs. The point to be kept in mind is that, since others too would be using this node, it is prudent not to inconvenience them by running large jobs.","title":"Running Interactive Jobs"},{"location":"job-schedule-manage/#submit-the-job","text":"To Submitting a simple standalone job , This is a simple submit script which is to be submitted sbatch job-script-name A sample Slurm job script #!/bin/sh #SBATCH --nodes 1 // specifies number of nodes #SBATCH --ntasks-per-node=40 // specifies core per node #SBATCH --time=06:50:20 // specifies maximum duration of run #SBATCH --job-name=lammps // specifies job name #SBATCH --output=job_output.txt //specifies output file name #SBATCH --partition=shortq // specifies queue name #SBATCH --ntasks=10 //specifies total no of cores required ########################################################## echo \u201cJob Submitted\u201d #load required modules module load ... #------------- run your commands here\u2014-----------------# mpirun -n $SLURM_NTASKS ... echo \u201cJob finished successfully\u201d","title":"Submit the Job"},{"location":"job-schedule-manage/#managing-jobs","text":"Madhava HPC Cluster extensively uses modules. The purpose of the module is to provide the production environment for a given application, outside of the application itself. This also specifies which version of the application is available for a given session. All applications and libraries are made available through module files. A User has to load the appropriate module from the available modules. module avail # This command lists all the available modules module load compilers/intel/parallel_studio_xe_2020.4.912 # This will load the intel compilers into your environment module unload compilers/intel/parallel_studio_xe_2020.4.912 # This will remove all environment setting related to intel compiler loaded previously module list #This will list currently loaded modules.","title":"Managing Jobs"},{"location":"job-schedule-manage/#list-partition","text":"sinfo displays information about nodes and partitions(queues). sinfo","title":"List Partition"},{"location":"job-schedule-manage/#list-jobs","text":"Monitoring jobs on SLURM can be done using the command squeue. squeue is used to view job and job step information for jobs managed by SLURM squeue","title":"List jobs"},{"location":"job-schedule-manage/#get-job-details","text":"scontrol can be used to report more detailed information about nodes, partitions, jobs, job steps, and configuration. scontrol show node - shows detailed information about compute nodes. scontrol show partition - shows detailed information about a specific partition scontrol show job - shows detailed information about a specific job or all jobs if no job id isgiven. scontrol update job - change attributes of submitted job.","title":"Get job details"},{"location":"job-schedule-manage/#suspend-a-job-root-only","text":"# scontrol suspend 135 # squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 135 shortq simple.s user1 S 0:13 1 compute01","title":"Suspend a job (root only):"},{"location":"job-schedule-manage/#resume-a-job-root-only","text":"# scontrol resume 135 # squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 135 shortq simple.s user1 R 0:13 1 compute01 Kill a job. Users can kill their own jobs, root can kill any job. $ scancel 135 $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)","title":"Resume a job (root only):"},{"location":"job-schedule-manage/#hold-a-job","text":"$ scontrol hold 139 Release a job: $ scontrol release 139","title":"Hold a job:"},{"location":"job-schedule-manage/#more-about-batch-jobs-slurm","text":"SLURM (Simple Linux Utility for Resource Management) is a workload manager that provides a framework for job queues, allocation of compute nodes, and the start and execution of jobs. It is important to note: Compilations are done on the login node. Only the execution is scheduled via SLURM on the compute/GPU nodes Upon Submission of a Job script, each job gets a unique Job Id. This can be obtained from the \u2018squeue\u2019 command. The Job Id is also appended to the output and error filenames.","title":"More about Batch Jobs (SLURM)"},{"location":"job-schedule-manage/#parameters-used-in-slurm-job-script","text":"The job flags are used with SBATCH command. The syntax for the SLURM directive in a script is \"#SBATCH \". Some of the flags are used with the srun and salloc commands. Resource Flag Syntax Description partition --partition=partition-name Partition is a queue for jobs. time --time=01:00:00 Time limit for the job. nodes --nodes=2 Number of compute nodes for for the job cpus/cores --ntasks-per-node=8 Corresponds to number of cores on the compute node job name --job-name=\"job-1\" Name of job output file --output=job-1.out Name of file for stdout. access --exclusive Exclusive access to computenodes resource --gres=gpu:2 Request use of GPUs on compute node","title":"Parameters used in SLURM job Script"},{"location":"job-schedule-manage/#some-useful-slurm-commands","text":"Sl No Purpose Command 1 To check the queue status squeue 2 To check the status/ availability of nodes sinfo 3 To cancel a job running scancel note: job id can be obtained by command squeue 4 To check the jobs of a particular user squeue -u 5 To list all running jobs of a user squeue -u -t RUNNING 6 To list all pending jobs of a user squeue -u -t PENDING 7 To cancel all the pending jobs for a user scancel -t PENDING -u username","title":"Some useful SLURM commands."},{"location":"pnq/","text":"Partition & QoS \u00b6 Partitions \u00b6 A partition is a set of compute nodes grouped logically based on their hardware features. The table below shows the available partitions and their properties / features in Madhava HPC Partition Default / Max Job duration nodes cores per node RAM(GB) per node State testq 01:00:00 compute[01-31] 40 192GB UP shortq infinite compute[01-31] 40 192GB UP medium infinite compute[01-31] 40 192GB UP longq infinite compute[01-31] 40 192GB UP testgpuq 01:00:00 compute[32-33] 40 192GB UP gpu q infinite compute[32-33] 40 192GB UP Quality of Service (QoS) \u00b6 Each QoS is assigned a set of limits to be applied to the job, dictating the limit in the resources and partitions that a job is entitled to request. The table below shows the available QoS in Madhava HPC and their allowed partitions / resources limits. Name Wall Time Max Jobs Per User Max Submit Per User Max Nodes Min Nodes Max Cores Resources testq 01:00:00 2 2 1 1 40 shortq infinite 4 5 1 1 40 medium infinite 3 4 3 2 120 longq infinite 1 1 8 5 320 testgpuq 01:00:00 2 2 1 1 40 2 GPU gpu q infinite 1 2 1 1 40 2 GPU Note Users are advised to specify a suitable QoS depending on the job\u2019s requirement. Note For those serial jobs or multi-threaded (OpenMP) jobs that can only be executed on a single node requested to uswe \"shortq\", for the jobs requires more running time then the \"mediumq\" and \u201clongq\u201d QoS is a more preferable one.","title":"Partition & Qos"},{"location":"pnq/#partition-qos","text":"","title":"Partition &amp; QoS"},{"location":"pnq/#partitions","text":"A partition is a set of compute nodes grouped logically based on their hardware features. The table below shows the available partitions and their properties / features in Madhava HPC Partition Default / Max Job duration nodes cores per node RAM(GB) per node State testq 01:00:00 compute[01-31] 40 192GB UP shortq infinite compute[01-31] 40 192GB UP medium infinite compute[01-31] 40 192GB UP longq infinite compute[01-31] 40 192GB UP testgpuq 01:00:00 compute[32-33] 40 192GB UP gpu q infinite compute[32-33] 40 192GB UP","title":"Partitions"},{"location":"pnq/#quality-of-service-qos","text":"Each QoS is assigned a set of limits to be applied to the job, dictating the limit in the resources and partitions that a job is entitled to request. The table below shows the available QoS in Madhava HPC and their allowed partitions / resources limits. Name Wall Time Max Jobs Per User Max Submit Per User Max Nodes Min Nodes Max Cores Resources testq 01:00:00 2 2 1 1 40 shortq infinite 4 5 1 1 40 medium infinite 3 4 3 2 120 longq infinite 1 1 8 5 320 testgpuq 01:00:00 2 2 1 1 40 2 GPU gpu q infinite 1 2 1 1 40 2 GPU Note Users are advised to specify a suitable QoS depending on the job\u2019s requirement. Note For those serial jobs or multi-threaded (OpenMP) jobs that can only be executed on a single node requested to uswe \"shortq\", for the jobs requires more running time then the \"mediumq\" and \u201clongq\u201d QoS is a more preferable one.","title":"Quality of Service (QoS)"},{"location":"pol-practice/","text":"Be a Good Cluster Citizen \u00b6 Usage Policy and Guidelines \u00b6 Application software available in the system / installed by user is to be used for academic purpose only and cannot be used for the monetary benefit of an individual or a company. To protect the security of the system, the user should neither provide his/her password nor allow other individuals to use his/her account. The system administrators may verify the above fact at any point of time. If found guilty, the user id will be cancelled without further reference to the user. Individuals who attempt to use accounts, files, system resources or other facilities without authorization or those who aid other individuals doing so, may be committing a criminal act and may be subjected to criminal prosecution. It is the responsibility of each individual user to know what effects the use of certain programs and/or facilities can have on other users and/or facilities, whether it may damage system resources or severely inconvenience other users currently using the system. System files and other application software installed by users and provided under license are not to be copied or tampered with. A Project Report is to be submitted at the end of the project.(1 page max.) Acknowledgement of the use of the center\u2019s facilities should be made in journal publications, dissertations, theses, conference publications and reports published by the users. Any outcomes of the project, in terms of publications (journal / conference proceedings etc.) should be communicated to the center. Student Accounts will be deleted and the user files removed on graduation. Best Practices of HPC \u00b6 Do not go over your storage quota. Exceeding your storage quota can lead to many problems including batch jobs failing, confusing error messages and the inability to use X11 forwarding. Be sure to routinely run the \"du -sh ~/ \" command to check your usage. If more space is needed then remove files. Do not run jobs on the Master node. When you connect to a cluster via SSH you land on the Master node which is shared by all users. The login node is reserved for submitting jobs, compiling codes, installing software and running short tests that use only a few CPU-cores and finish within a few minutes. Anything more intensive must be submitted to the Slurm job scheduler as either a batch or interactive job. Failure to comply with this rule may result in your account being suspended. For a quick Start please visit here Do not allocate more than one CPU-core for serial jobs. Serial codes cannot run in parallel so using more than one CPU-core will not cause the job to run faster. Instead, doing so will waste resources. See the Slurm page for tips on figuring out if your code can run in parallel and for information about Job Arrays which allow one to run many jobs simultaneously. Do not run jobs with a parallel code without first conducting a scaling analysis. If your code runs in parallel then you need to determine the optimal number of nodes and CPU-cores to use. The same is true if it can use multiple GPUs. To do this, perform a scaling analysis as described in Choosing the Number of Nodes, CPU-cores and GPUs. Do not request a GPU for a code that can only use CPUs. Only codes that have been explicitly written to use GPUs can take advantage of GPUs. Allocating a GPU for a CPU-only code will not speed-up the execution time but it will increase your queue time, waste resources. Furthermore, some codes are written to use only a single GPU. For more see GPU Computing and Choosing the Number of Nodes, CPU-cores and GPUs. Do not load environment modules using only the partial name. You should always specify the full name of the environment module (e.g., module load compilers/intel/parallel_studio_xe_2020.4.912) and on some clusters failing to do so will result in an error. Also, you should avoid loading environment modules in your ~/.bashrc file. Instead, do this in Slurm scripts and on the command line when needed. Please do not use spaces while creating the directories and files.","title":"Be a Good Cluster Citizen"},{"location":"pol-practice/#be-a-good-cluster-citizen","text":"","title":"Be a Good Cluster Citizen"},{"location":"pol-practice/#usage-policy-and-guidelines","text":"Application software available in the system / installed by user is to be used for academic purpose only and cannot be used for the monetary benefit of an individual or a company. To protect the security of the system, the user should neither provide his/her password nor allow other individuals to use his/her account. The system administrators may verify the above fact at any point of time. If found guilty, the user id will be cancelled without further reference to the user. Individuals who attempt to use accounts, files, system resources or other facilities without authorization or those who aid other individuals doing so, may be committing a criminal act and may be subjected to criminal prosecution. It is the responsibility of each individual user to know what effects the use of certain programs and/or facilities can have on other users and/or facilities, whether it may damage system resources or severely inconvenience other users currently using the system. System files and other application software installed by users and provided under license are not to be copied or tampered with. A Project Report is to be submitted at the end of the project.(1 page max.) Acknowledgement of the use of the center\u2019s facilities should be made in journal publications, dissertations, theses, conference publications and reports published by the users. Any outcomes of the project, in terms of publications (journal / conference proceedings etc.) should be communicated to the center. Student Accounts will be deleted and the user files removed on graduation.","title":"Usage Policy and Guidelines"},{"location":"pol-practice/#best-practices-of-hpc","text":"Do not go over your storage quota. Exceeding your storage quota can lead to many problems including batch jobs failing, confusing error messages and the inability to use X11 forwarding. Be sure to routinely run the \"du -sh ~/ \" command to check your usage. If more space is needed then remove files. Do not run jobs on the Master node. When you connect to a cluster via SSH you land on the Master node which is shared by all users. The login node is reserved for submitting jobs, compiling codes, installing software and running short tests that use only a few CPU-cores and finish within a few minutes. Anything more intensive must be submitted to the Slurm job scheduler as either a batch or interactive job. Failure to comply with this rule may result in your account being suspended. For a quick Start please visit here Do not allocate more than one CPU-core for serial jobs. Serial codes cannot run in parallel so using more than one CPU-core will not cause the job to run faster. Instead, doing so will waste resources. See the Slurm page for tips on figuring out if your code can run in parallel and for information about Job Arrays which allow one to run many jobs simultaneously. Do not run jobs with a parallel code without first conducting a scaling analysis. If your code runs in parallel then you need to determine the optimal number of nodes and CPU-cores to use. The same is true if it can use multiple GPUs. To do this, perform a scaling analysis as described in Choosing the Number of Nodes, CPU-cores and GPUs. Do not request a GPU for a code that can only use CPUs. Only codes that have been explicitly written to use GPUs can take advantage of GPUs. Allocating a GPU for a CPU-only code will not speed-up the execution time but it will increase your queue time, waste resources. Furthermore, some codes are written to use only a single GPU. For more see GPU Computing and Choosing the Number of Nodes, CPU-cores and GPUs. Do not load environment modules using only the partial name. You should always specify the full name of the environment module (e.g., module load compilers/intel/parallel_studio_xe_2020.4.912) and on some clusters failing to do so will result in an error. Also, you should avoid loading environment modules in your ~/.bashrc file. Instead, do this in Slurm scripts and on the command line when needed. Please do not use spaces while creating the directories and files.","title":"Best Practices of HPC"},{"location":"slurm-jobscript/","text":"SLURM Job script \u00b6 To execute a program in the cluster system, a user has to write a batch script and submit it to the SLURM job scheduler. Sample of general SLURM scripts are located in each user\u2019s hpc2021 home directory ~/slurm-samples and user guide for individual software can be referenced. Sample job script \u00b6 In the example job script (script.cmd) below, it requests the following resources and actual programs/commands to be executed. Name the job as \u201cpilot_study\u201d for easy reference. Request for the \u201cshortq\u201d partition Request for \u201cshortq\u201d QoS. Request for allocation of 40 CPU cores contributed from a total of one compute node. Request for 10GB physical RAM. Request for job execution 3 days and 10 hours ( The job would be terminated by SLURM after the specified amount of time no matter it has finished or not). Write the standard output and standard error to the file \u201cpilot_study_2021.out\u201d and \u201cpilot_study_2021.err\u201d respectively under the folder where the job is submitted. The path supports the use of replacement symbols. #!/bin/bash #SBATCH --job-name=pilot_study # 1. Job name #SBATCH --partition=shortq # 2. Request a partition #SBATCH --ntasks=40 # 3. Request total number of tasks (MPI workers) #SBATCH --nodes=1 # 4. Request number of node(s) #SBATCH --mem=10G # 5. Request total amount of RAM #SBATCH --time=3-10:00:00 # 6. Job execution duration limit day-hour:min:sec #SBATCH --output=%x_%j.out # 7. Standard output log as $job_name_$job_id.out #SBATCH --error=%x_%j.err # 8. Standard error log as $job_name_$job_id.err ##print the start time date command1 ... command2 ... command3 ... ##print the end time date SLURM Job Directives \u00b6 A SLURM script includes a list of SLURM job directives at the top of the file, where each line starts with #SBATCH followed by option name to value pairs to tell the job scheduler the resources that a job requests. Long Option Short Option Default value Description --job-name -J file name of job script User defined name to identify a job --partition -p intel Partition where a job to be executed --time -t 24:00:00 Specify a limit on the maximum execution time (walltime) for the job (D-HH:MM:SS) .For example, -t 1- is one day, -t 6:00:00 is 6 hours --nodes -N Total number of node(s) --ntasks -n 1 Number of tasks (MPI workers) --ntasks-per-node Number of tasks per node --cpus-per-task -c 1 Number of CPUs required per task --mem Amount of memory allocated per node. Different units can be specified using the suffix [K --mem-per-cpu Amount of memory allocated per cpu per code (For multicore jobs). Different units can be specified using the suffix [K --exclude -x Explicitly exclude certain nodes from the resources granted to the job. More SLURM directives are available here Running Serial / Single Threaded Jobs using a CPU on a node \u00b6 Serial or single CPU core jobs are those jobs that can only make use of one CPU on a node. A SLURM batch script below will request for a single CPU on a node with default amount of RAM for 30 minutes in testq partition. #!/bin/bash #SBATCH --job-name=test-job1 #SBATCH --ntasks=1 #SBATCH --partition=shortq #SBATCH --time=00:30:00 command1 ... Running Multi-threaded Jobs using multiple CPU cores on a node \u00b6 For those jobs that can leverage multiple CPU cores on a node via creating multiple threads within a process (e.g. OpenMP), a SLURM batch script below may be used that requests for allocation to a task with 8 CPU cores on a single node and 6GB RAM per core (Totally 6GB x 8 = 48GB RAM on a node ) for 1 hour in shortq partition. Note --cpus-per-task should be no more than the number of cores on a compute node you request. You may want to experiment with the number of threads for your job to determine the optimal number, as computational speed does not always increase with more threads. Note that if --cpus-per-task is fewer than the number of cores on a node, your job will not make full use of the node. Note For program that can only use a single CPU, requesting for more CPU will NOT make it run faster but will likely make the queuing time longer. eg: #!/bin/bash #SBATCH --job-name=pilot_study #SBATCH --partition=shortq #SBATCH --ntasks=1 #SBATCH --nodes=1 #SBATCH --mem-percpu=6G #SBATCH --time=01:00:00 #SBATCH --cpus-per-task=8 #For jobs supporting OpenMP, assign the value of the requested CPU cores to the OMP_NUM_THREADS variable #that would be automatically passed to your command supporting OpenMP export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK} command1 ... #For jobs not supporting OpenMP, supply the value of the requested CPU cores as command-line argument to the command command2 -t ${SLURM_CPUS_PER_TASK} ... Running MPI jobs using multiple nodes \u00b6 Message Passing Interface (MPI) is a standardized and portable message-passing standard designed to allow for execution of programs using CPUs on multiple nodes where CPUs across nodes communicate over the network. The MPI standard defines the syntax and semantics of library routines that are useful to a wide range of users writing portable message-passing programs in C, C++, and Fortran. Intel MPI and OpenMPI are available in Madhava HPC system and SLURM jobs may make use of either MPI implementations. Note Requesting for multiple nodes and /or loading any MPI modules may not necessarily make your code faster, your code must be MPI aware to use MPI. Even though running a non-MPI code with mpirun might possibly succeed, you will most likely have every core assigned to your job running the exact computation, duplicating each others work, and wasting resources. Note The version of the MPI commands you run must match the version of the MPI library used in compiling your code, or your job is likely to fail. And the version of the MPI daemons started on all the nodes for your job must also match. For example, an MPI program compiled with Intel MPI compilers should be executed using Intel MPI runtime instead of Open MPI runtime. A SLURM batch script below requests for allocation to 40 tasks (MPI processes) each use a single core from two nodes and 3GB RAM per core for 1 hour in mediumq #!/bin/bash #SBATCH --job-name=run_mpi #SBATCH --partition=mediumq #SBATCH --ntasks=40 #SBATCH --nodes=2 #SBATCH --mem=10G #SBATCH --time=01:00:00 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=3G #SBATCH --output=%x_%j.out #SBATCH --error=%x_%j.err cd ${SLURM_SUBMIT_DIR} #Load the environment for Intel MPI module load compilers/intel/parallel_studio_xe_2020.4.912 #run the program supporting MPI with the \"mpirun\" command #The -n option is not required since mpirun will automatically determine from SLURM settings mpirun ./program_mpi This example make use of all the cores on two, 20-core nodes in the \u201cmediumq\u201d partition. If same number of tasks (i.e. 64) is requested from partition \u201camd\u201d, you should set \u201c--nodes=1\u201d so that all 64 cores will be allocated from a single AMD (64-core or 128-core) node . Otherwise, SLURM will assign 64 CPUs from 2 compute nodes which would induce unnecessary inter-node communication overhead. Running hybrid OpenMP/MPI jobs using multiple nodes \u00b6 For those jobs that support both OpenMP and MPI, a SLURM batch script may specify the number of MPI tasks to run and the number of CPU core that each task should use. A SLURM batch script below requests for allocation of 2 nodes and 80 CPU cores in total for 1 hour in mediumq. Each compute node runs 2 MPI tasks, where each MPI task uses 20 CPU core and each core uses 3GB RAM. This would make use of all the cores on two, 40-core nodes in the \u201cintel\u201d partition. #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks-per-node=2 #SBATCH --cpus-per-task=20 #SBATCH --mem-per-cpu=3G #SBATCH --time=01:00:00 cd ${SLURM_SUBMIT_DIR} #Load the environment for Intel MPI module load compilers/intel/parallel_studio_xe_2020.4.912 #assign the value of the requested CPU cores per task to the OMP_NUM_THREADS variable export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK} # run the program supporting MPI with the \"mpirun\" command. # The -n option is not required since mpirun will automatically determine from SLURM settings mpirun ./program_mpi-omp Sample MPI & hybrid MPI/OpenMP codes and the corresponding SLURM scripts are available at............................. Running jobs using GPU \u00b6 Note \u2757Your code must be GPU aware to benefit from nodes with GPU, otherwise other partition without GPU should be used. A SLURM batch script below request for 8 CPU cores and 2 GPU cards from one compute node in the \u201cgpuq\u201d partition #!/bin/bash #SBATCH --job-name=run_gpu #SBATCH --partition=gpuq #SBATCH --ntasks=1 #SBATCH --nodes=1 #SBATCH --cpus-per-task=8 ## Load the environment module for Nvidia CUDA module load compilers/nvidia/cuda/11.0 commands","title":"Slurm Job Script"},{"location":"slurm-jobscript/#slurm-job-script","text":"To execute a program in the cluster system, a user has to write a batch script and submit it to the SLURM job scheduler. Sample of general SLURM scripts are located in each user\u2019s hpc2021 home directory ~/slurm-samples and user guide for individual software can be referenced.","title":"SLURM Job script"},{"location":"slurm-jobscript/#sample-job-script","text":"In the example job script (script.cmd) below, it requests the following resources and actual programs/commands to be executed. Name the job as \u201cpilot_study\u201d for easy reference. Request for the \u201cshortq\u201d partition Request for \u201cshortq\u201d QoS. Request for allocation of 40 CPU cores contributed from a total of one compute node. Request for 10GB physical RAM. Request for job execution 3 days and 10 hours ( The job would be terminated by SLURM after the specified amount of time no matter it has finished or not). Write the standard output and standard error to the file \u201cpilot_study_2021.out\u201d and \u201cpilot_study_2021.err\u201d respectively under the folder where the job is submitted. The path supports the use of replacement symbols. #!/bin/bash #SBATCH --job-name=pilot_study # 1. Job name #SBATCH --partition=shortq # 2. Request a partition #SBATCH --ntasks=40 # 3. Request total number of tasks (MPI workers) #SBATCH --nodes=1 # 4. Request number of node(s) #SBATCH --mem=10G # 5. Request total amount of RAM #SBATCH --time=3-10:00:00 # 6. Job execution duration limit day-hour:min:sec #SBATCH --output=%x_%j.out # 7. Standard output log as $job_name_$job_id.out #SBATCH --error=%x_%j.err # 8. Standard error log as $job_name_$job_id.err ##print the start time date command1 ... command2 ... command3 ... ##print the end time date","title":"Sample job script"},{"location":"slurm-jobscript/#slurm-job-directives","text":"A SLURM script includes a list of SLURM job directives at the top of the file, where each line starts with #SBATCH followed by option name to value pairs to tell the job scheduler the resources that a job requests. Long Option Short Option Default value Description --job-name -J file name of job script User defined name to identify a job --partition -p intel Partition where a job to be executed --time -t 24:00:00 Specify a limit on the maximum execution time (walltime) for the job (D-HH:MM:SS) .For example, -t 1- is one day, -t 6:00:00 is 6 hours --nodes -N Total number of node(s) --ntasks -n 1 Number of tasks (MPI workers) --ntasks-per-node Number of tasks per node --cpus-per-task -c 1 Number of CPUs required per task --mem Amount of memory allocated per node. Different units can be specified using the suffix [K --mem-per-cpu Amount of memory allocated per cpu per code (For multicore jobs). Different units can be specified using the suffix [K --exclude -x Explicitly exclude certain nodes from the resources granted to the job. More SLURM directives are available here","title":"SLURM Job Directives"},{"location":"slurm-jobscript/#running-serial-single-threaded-jobs-using-a-cpu-on-a-node","text":"Serial or single CPU core jobs are those jobs that can only make use of one CPU on a node. A SLURM batch script below will request for a single CPU on a node with default amount of RAM for 30 minutes in testq partition. #!/bin/bash #SBATCH --job-name=test-job1 #SBATCH --ntasks=1 #SBATCH --partition=shortq #SBATCH --time=00:30:00 command1 ...","title":"Running Serial / Single Threaded Jobs using a CPU on a node"},{"location":"slurm-jobscript/#running-multi-threaded-jobs-using-multiple-cpu-cores-on-a-node","text":"For those jobs that can leverage multiple CPU cores on a node via creating multiple threads within a process (e.g. OpenMP), a SLURM batch script below may be used that requests for allocation to a task with 8 CPU cores on a single node and 6GB RAM per core (Totally 6GB x 8 = 48GB RAM on a node ) for 1 hour in shortq partition. Note --cpus-per-task should be no more than the number of cores on a compute node you request. You may want to experiment with the number of threads for your job to determine the optimal number, as computational speed does not always increase with more threads. Note that if --cpus-per-task is fewer than the number of cores on a node, your job will not make full use of the node. Note For program that can only use a single CPU, requesting for more CPU will NOT make it run faster but will likely make the queuing time longer. eg: #!/bin/bash #SBATCH --job-name=pilot_study #SBATCH --partition=shortq #SBATCH --ntasks=1 #SBATCH --nodes=1 #SBATCH --mem-percpu=6G #SBATCH --time=01:00:00 #SBATCH --cpus-per-task=8 #For jobs supporting OpenMP, assign the value of the requested CPU cores to the OMP_NUM_THREADS variable #that would be automatically passed to your command supporting OpenMP export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK} command1 ... #For jobs not supporting OpenMP, supply the value of the requested CPU cores as command-line argument to the command command2 -t ${SLURM_CPUS_PER_TASK} ...","title":"Running Multi-threaded Jobs using multiple CPU cores on a node"},{"location":"slurm-jobscript/#running-mpi-jobs-using-multiple-nodes","text":"Message Passing Interface (MPI) is a standardized and portable message-passing standard designed to allow for execution of programs using CPUs on multiple nodes where CPUs across nodes communicate over the network. The MPI standard defines the syntax and semantics of library routines that are useful to a wide range of users writing portable message-passing programs in C, C++, and Fortran. Intel MPI and OpenMPI are available in Madhava HPC system and SLURM jobs may make use of either MPI implementations. Note Requesting for multiple nodes and /or loading any MPI modules may not necessarily make your code faster, your code must be MPI aware to use MPI. Even though running a non-MPI code with mpirun might possibly succeed, you will most likely have every core assigned to your job running the exact computation, duplicating each others work, and wasting resources. Note The version of the MPI commands you run must match the version of the MPI library used in compiling your code, or your job is likely to fail. And the version of the MPI daemons started on all the nodes for your job must also match. For example, an MPI program compiled with Intel MPI compilers should be executed using Intel MPI runtime instead of Open MPI runtime. A SLURM batch script below requests for allocation to 40 tasks (MPI processes) each use a single core from two nodes and 3GB RAM per core for 1 hour in mediumq #!/bin/bash #SBATCH --job-name=run_mpi #SBATCH --partition=mediumq #SBATCH --ntasks=40 #SBATCH --nodes=2 #SBATCH --mem=10G #SBATCH --time=01:00:00 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=3G #SBATCH --output=%x_%j.out #SBATCH --error=%x_%j.err cd ${SLURM_SUBMIT_DIR} #Load the environment for Intel MPI module load compilers/intel/parallel_studio_xe_2020.4.912 #run the program supporting MPI with the \"mpirun\" command #The -n option is not required since mpirun will automatically determine from SLURM settings mpirun ./program_mpi This example make use of all the cores on two, 20-core nodes in the \u201cmediumq\u201d partition. If same number of tasks (i.e. 64) is requested from partition \u201camd\u201d, you should set \u201c--nodes=1\u201d so that all 64 cores will be allocated from a single AMD (64-core or 128-core) node . Otherwise, SLURM will assign 64 CPUs from 2 compute nodes which would induce unnecessary inter-node communication overhead.","title":"Running MPI jobs using multiple nodes"},{"location":"slurm-jobscript/#running-hybrid-openmpmpi-jobs-using-multiple-nodes","text":"For those jobs that support both OpenMP and MPI, a SLURM batch script may specify the number of MPI tasks to run and the number of CPU core that each task should use. A SLURM batch script below requests for allocation of 2 nodes and 80 CPU cores in total for 1 hour in mediumq. Each compute node runs 2 MPI tasks, where each MPI task uses 20 CPU core and each core uses 3GB RAM. This would make use of all the cores on two, 40-core nodes in the \u201cintel\u201d partition. #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks-per-node=2 #SBATCH --cpus-per-task=20 #SBATCH --mem-per-cpu=3G #SBATCH --time=01:00:00 cd ${SLURM_SUBMIT_DIR} #Load the environment for Intel MPI module load compilers/intel/parallel_studio_xe_2020.4.912 #assign the value of the requested CPU cores per task to the OMP_NUM_THREADS variable export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK} # run the program supporting MPI with the \"mpirun\" command. # The -n option is not required since mpirun will automatically determine from SLURM settings mpirun ./program_mpi-omp Sample MPI & hybrid MPI/OpenMP codes and the corresponding SLURM scripts are available at.............................","title":"Running hybrid OpenMP/MPI jobs using multiple nodes"},{"location":"slurm-jobscript/#running-jobs-using-gpu","text":"Note \u2757Your code must be GPU aware to benefit from nodes with GPU, otherwise other partition without GPU should be used. A SLURM batch script below request for 8 CPU cores and 2 GPU cards from one compute node in the \u201cgpuq\u201d partition #!/bin/bash #SBATCH --job-name=run_gpu #SBATCH --partition=gpuq #SBATCH --ntasks=1 #SBATCH --nodes=1 #SBATCH --cpus-per-task=8 ## Load the environment module for Nvidia CUDA module load compilers/nvidia/cuda/11.0 commands","title":"Running jobs using GPU"},{"location":"slurm-manage/","text":"SLURM Job Management \u00b6 After a job is submitted to SLURM, user may check the job status with commands sq or showq as described below. Show any running/pending jobs $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 23598 shortq dphpcap_ p210006c R 13-23:48:34 1 compute26 23707 shortq dphpcap_ p210006c R 11-15:37:20 1 compute27 23708 shortq dphpcap_ p210006c R 11-13:07:41 1 compute17 23716 shortq ts1-opt p170072c R 11-08:32:55 1 compute06 23752 shortq dphpcap_ p210006c R 5-02:59:36 1 compute23 23872 shortq Ge-m3-bs p180028c R 7-16:37:59 1 compute12 23949 mediumq nfkappa8 p140114n R 5-07:31:59 3 compute[01-02,23] 23953 shortq as-origi p200019c R 6-02:59:31 1 compute05 23970 gpuq Sol-2 p180089p R 3-15:38:49 1 compute32 23976 mediumq Au8-O2 p180089p R 5-13:23:58 2 compute[05,25] 24004 shortq mix raghuc R 3-06:19:34 1 compute29 24020 gpuq e8r_fexo tomskari R 3-03:13:48 1 compute33 24023 gpuq 58RPE p210139b R 3-01:11:50 1 compute33 24038 shortq mix2 raghuc R 2-21:38:58 1 compute28 24039 shortq mix1 raghuc R 2-21:38:41 1 compute30 24055 mediumq mix3 raghuc R 1-13:28:53 2 compute[01-02] 24056 shortq Cu8_o21 p180089p R 1-13:28:53 1 compute03 24079 mediumq md2 p200028p R 1-20:38:10 2 compute[26-27] 24086 mediumq Ni_ads p220106p R 1-17:05:33 2 compute[17,24] 24119 shortq NEB1 p200028p R 14:49:51 1 compute31 24124 mediumq nfkappa8 p140114n R 17:44:16 2 compute[19,25] 24125 longq nfkappa8 p140114n R 17:39:01 5 compute[03,05,11,19-20] 24127 shortq elabqa p170030c R 5:43:32 1 compute20 24130 shortq zlabqa p170030c R 5:39:36 1 compute24 24131 shortq zlabqa p170030c R 5:39:11 1 compute11 24133 shortq bcc30 p190146m R 4:50:52 1 compute12 24146 shortq NEB2_2 p200028p R 35:49 1 compute09 24147 shortq visc8p2v p140114n R 1:27 1 compute13 Show specific job, \u00b6 squeue -j <JobID> $ squeue -j 123456 Show jobs in a specific partition, \u00b6 squeue -p <partition> $ squeue -p shortq Show running job \u00b6 $ squeue -t R Show pending job \u00b6 $ squeue -t PD Job information provided Description JOBID : Job ID PARTITION : Partition NAME : Job name given ST (status) : TIME : Running Time NODELIST : List of the nodes which the job is using NODELIST(REASON) : Show the reason that explain the current job status Status Description R Running PD Pending (queuing) CD Completed (exit code 0 \u2014 without error) F Failure (exit code non-zero) DL Failure (job terminated on deadline) Reason Description Priority The job is waiting for higher priority job(s) to complete Dependency The job is waiting for a dependent job to complete Resources The job is waiting for resources to become available MaxJobsPerUser Maximum number of jobs for users are in running Delete / cancel a job \u00b6 $ scancel <JobID> Delete / cancel all jobs for a user \u00b6 $ scancel -u <Username> Update attributes of submitted jobs \u00b6 Update walltime request of a queuing job (a job which is pending and not yet start to run) to 1 hour. $ scontrol update jobid=<JobID> TimeLimit=01:00:00 Check Partition/Node Usage \u00b6 User can use command plist to check the status of partitions and nodes $ sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST testq up 1:00:00 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] testq up 1:00:00 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] shortq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] shortq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] mediumq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] mediumq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] longq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] longq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] testgpuq up 1:00:00 1 mix compute32 testgpuq up 1:00:00 1 alloc compute33 gpuq up infinite 1 mix compute32 gpuq up infinite 1 alloc compute33","title":"Slurm Job Management"},{"location":"slurm-manage/#slurm-job-management","text":"After a job is submitted to SLURM, user may check the job status with commands sq or showq as described below. Show any running/pending jobs $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 23598 shortq dphpcap_ p210006c R 13-23:48:34 1 compute26 23707 shortq dphpcap_ p210006c R 11-15:37:20 1 compute27 23708 shortq dphpcap_ p210006c R 11-13:07:41 1 compute17 23716 shortq ts1-opt p170072c R 11-08:32:55 1 compute06 23752 shortq dphpcap_ p210006c R 5-02:59:36 1 compute23 23872 shortq Ge-m3-bs p180028c R 7-16:37:59 1 compute12 23949 mediumq nfkappa8 p140114n R 5-07:31:59 3 compute[01-02,23] 23953 shortq as-origi p200019c R 6-02:59:31 1 compute05 23970 gpuq Sol-2 p180089p R 3-15:38:49 1 compute32 23976 mediumq Au8-O2 p180089p R 5-13:23:58 2 compute[05,25] 24004 shortq mix raghuc R 3-06:19:34 1 compute29 24020 gpuq e8r_fexo tomskari R 3-03:13:48 1 compute33 24023 gpuq 58RPE p210139b R 3-01:11:50 1 compute33 24038 shortq mix2 raghuc R 2-21:38:58 1 compute28 24039 shortq mix1 raghuc R 2-21:38:41 1 compute30 24055 mediumq mix3 raghuc R 1-13:28:53 2 compute[01-02] 24056 shortq Cu8_o21 p180089p R 1-13:28:53 1 compute03 24079 mediumq md2 p200028p R 1-20:38:10 2 compute[26-27] 24086 mediumq Ni_ads p220106p R 1-17:05:33 2 compute[17,24] 24119 shortq NEB1 p200028p R 14:49:51 1 compute31 24124 mediumq nfkappa8 p140114n R 17:44:16 2 compute[19,25] 24125 longq nfkappa8 p140114n R 17:39:01 5 compute[03,05,11,19-20] 24127 shortq elabqa p170030c R 5:43:32 1 compute20 24130 shortq zlabqa p170030c R 5:39:36 1 compute24 24131 shortq zlabqa p170030c R 5:39:11 1 compute11 24133 shortq bcc30 p190146m R 4:50:52 1 compute12 24146 shortq NEB2_2 p200028p R 35:49 1 compute09 24147 shortq visc8p2v p140114n R 1:27 1 compute13","title":"SLURM Job Management"},{"location":"slurm-manage/#show-specific-job","text":"squeue -j <JobID> $ squeue -j 123456","title":"Show specific job,"},{"location":"slurm-manage/#show-jobs-in-a-specific-partition","text":"squeue -p <partition> $ squeue -p shortq","title":"Show jobs in a specific partition,"},{"location":"slurm-manage/#show-running-job","text":"$ squeue -t R","title":"Show running job"},{"location":"slurm-manage/#show-pending-job","text":"$ squeue -t PD Job information provided Description JOBID : Job ID PARTITION : Partition NAME : Job name given ST (status) : TIME : Running Time NODELIST : List of the nodes which the job is using NODELIST(REASON) : Show the reason that explain the current job status Status Description R Running PD Pending (queuing) CD Completed (exit code 0 \u2014 without error) F Failure (exit code non-zero) DL Failure (job terminated on deadline) Reason Description Priority The job is waiting for higher priority job(s) to complete Dependency The job is waiting for a dependent job to complete Resources The job is waiting for resources to become available MaxJobsPerUser Maximum number of jobs for users are in running","title":"Show pending job"},{"location":"slurm-manage/#delete-cancel-a-job","text":"$ scancel <JobID>","title":"Delete / cancel a job"},{"location":"slurm-manage/#delete-cancel-all-jobs-for-a-user","text":"$ scancel -u <Username>","title":"Delete / cancel all jobs for a user"},{"location":"slurm-manage/#update-attributes-of-submitted-jobs","text":"Update walltime request of a queuing job (a job which is pending and not yet start to run) to 1 hour. $ scontrol update jobid=<JobID> TimeLimit=01:00:00","title":"Update attributes of submitted jobs"},{"location":"slurm-manage/#check-partitionnode-usage","text":"User can use command plist to check the status of partitions and nodes $ sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST testq up 1:00:00 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] testq up 1:00:00 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] shortq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] shortq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] mediumq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] mediumq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] longq up infinite 13 mix compute[01-03,06,11-12,15,19-20,23-25,27] longq up infinite 18 alloc compute[04-05,07-10,13-14,16-18,21-22,26,28-31] testgpuq up 1:00:00 1 mix compute32 testgpuq up 1:00:00 1 alloc compute33 gpuq up infinite 1 mix compute32 gpuq up infinite 1 alloc compute33","title":"Check Partition/Node Usage"},{"location":"slurm/","text":"SLURM \u00b6 The tool we use to manage the submission, scheduling and management of jobs in Madhava HPC is called SLURM. On a login node, user writes a batch script and submit it to the queue manager to schedule for execution in the compute nodes. The submitted job then queue up until the requested system resources is allocated. The queue manager will schedule a job to run on the queue (or partition in SLURM) according to a predetermined site policy designated to balance competing user needs and to maximize efficient use of cluster resources. Each job\u2019s position in the queue is determined through the fairshare algorithm, which depends on a number of factors (e.g. size of job, time requirement, job queuing time, etc). The HPC system is set up to support large computation jobs. Maximum CPUs and processing time limits are summarized in the tables below. Please note that the limits are subject to change without notice. Cheat sheet for SLURM job scheduler is available at here Partition & QoS Job Scripts Job Array Job Dependencies Job Submission Job Management","title":"Slurm"},{"location":"slurm/#slurm","text":"The tool we use to manage the submission, scheduling and management of jobs in Madhava HPC is called SLURM. On a login node, user writes a batch script and submit it to the queue manager to schedule for execution in the compute nodes. The submitted job then queue up until the requested system resources is allocated. The queue manager will schedule a job to run on the queue (or partition in SLURM) according to a predetermined site policy designated to balance competing user needs and to maximize efficient use of cluster resources. Each job\u2019s position in the queue is determined through the fairshare algorithm, which depends on a number of factors (e.g. size of job, time requirement, job queuing time, etc). The HPC system is set up to support large computation jobs. Maximum CPUs and processing time limits are summarized in the tables below. Please note that the limits are subject to change without notice. Cheat sheet for SLURM job scheduler is available at here Partition & QoS Job Scripts Job Array Job Dependencies Job Submission Job Management","title":"SLURM"},{"location":"software-catalog/","text":"Software Catalogue \u00b6 This page provides links to the pages describing a number of the individual softwares installed centrally on MADHAVA. The pages contain information on running jobs (including example job submission scripts). Software Description Amber A package of molecular simulation programs and analysis tools. Anaconda3 Autodock CESM Community Earth System Model, or CESM, is a fully-coupled, community, global climate model that provides state-of-the-art computer simulations of the Earth's past, present, and future climate states. DIVEMESH Gaussian GROMACS GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers. LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) a classical molecular dynamics code. MFIX Molpro Molpro is a complete system of ab initio programs for molecular electronic structure calculations, designed and maintained by H.-J. Werner and P. J. Knowles, and containing contributions from a number of other authors. As distinct from other commonly used quantum chemistry packages, the emphasis is on highly accurate computations, with extensive treatment of the electron correlation problem through the multiconfiguration-reference CI, coupled cluster and associated methods. OpenFOAM OpenFOAM is an open-source toolbox for computational fluid dynamics. OpenFOAM consists of generic tools to simulate complex physics for a variety of fields of interest, from fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics, electromagnetism and the pricing of financial options. The core technology of OpenFOAM is a flexible set of modules written in C++. These are used to build solvers and utilities to perform pre- and post-processing tasks ranging from simple data manipulation to visualisation and mesh processing. Quantum Espresso Quantum Espresso is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. REEF3D SIESTA (Spanish Initiative for Electronic Simulations with Thousands of Atoms) is a program to perform electronic structure calculations and ab initio molecular dynamics simulations of molecules and solids. Wavewatch Xbeach VASP A package for ab initio, quantum-mechanical, molecular dynamics simulations.","title":"Software Catalog"},{"location":"software-catalog/#software-catalogue","text":"This page provides links to the pages describing a number of the individual softwares installed centrally on MADHAVA. The pages contain information on running jobs (including example job submission scripts). Software Description Amber A package of molecular simulation programs and analysis tools. Anaconda3 Autodock CESM Community Earth System Model, or CESM, is a fully-coupled, community, global climate model that provides state-of-the-art computer simulations of the Earth's past, present, and future climate states. DIVEMESH Gaussian GROMACS GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers. LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) a classical molecular dynamics code. MFIX Molpro Molpro is a complete system of ab initio programs for molecular electronic structure calculations, designed and maintained by H.-J. Werner and P. J. Knowles, and containing contributions from a number of other authors. As distinct from other commonly used quantum chemistry packages, the emphasis is on highly accurate computations, with extensive treatment of the electron correlation problem through the multiconfiguration-reference CI, coupled cluster and associated methods. OpenFOAM OpenFOAM is an open-source toolbox for computational fluid dynamics. OpenFOAM consists of generic tools to simulate complex physics for a variety of fields of interest, from fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics, electromagnetism and the pricing of financial options. The core technology of OpenFOAM is a flexible set of modules written in C++. These are used to build solvers and utilities to perform pre- and post-processing tasks ranging from simple data manipulation to visualisation and mesh processing. Quantum Espresso Quantum Espresso is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. REEF3D SIESTA (Spanish Initiative for Electronic Simulations with Thousands of Atoms) is a program to perform electronic structure calculations and ab initio molecular dynamics simulations of molecules and solids. Wavewatch Xbeach VASP A package for ab initio, quantum-mechanical, molecular dynamics simulations.","title":"Software Catalogue"},{"location":"software-stack/","text":"Software Catalogue \u00b6 This page provides links to the pages describing a number of the individual softwares installed centrally on MADHAVA. The pages contain information on running jobs (including example job submission scripts). Software Description Amber A package of molecular simulation programs and analysis tools. Anaconda3 Autodock CESM Community Earth System Model, or CESM, is a fully-coupled, community, global climate model that provides state-of-the-art computer simulations of the Earth's past, present, and future climate states. DIVEMESH Gaussian GROMACS GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers. LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) a classical molecular dynamics code. MFIX Molpro Molpro is a complete system of ab initio programs for molecular electronic structure calculations, designed and maintained by H.-J. Werner and P. J. Knowles, and containing contributions from a number of other authors. As distinct from other commonly used quantum chemistry packages, the emphasis is on highly accurate computations, with extensive treatment of the electron correlation problem through the multiconfiguration-reference CI, coupled cluster and associated methods. OpenFOAM OpenFOAM is an open-source toolbox for computational fluid dynamics. OpenFOAM consists of generic tools to simulate complex physics for a variety of fields of interest, from fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics, electromagnetism and the pricing of financial options. The core technology of OpenFOAM is a flexible set of modules written in C++. These are used to build solvers and utilities to perform pre- and post-processing tasks ranging from simple data manipulation to visualisation and mesh processing. Quantum Espresso Quantum Espresso is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. REEF3D SIESTA (Spanish Initiative for Electronic Simulations with Thousands of Atoms) is a program to perform electronic structure calculations and ab initio molecular dynamics simulations of molecules and solids. Wavewatch Xbeach VASP A package for ab initio, quantum-mechanical, molecular dynamics simulations.","title":"Madhava Software Catalogue"},{"location":"software-stack/#software-catalogue","text":"This page provides links to the pages describing a number of the individual softwares installed centrally on MADHAVA. The pages contain information on running jobs (including example job submission scripts). Software Description Amber A package of molecular simulation programs and analysis tools. Anaconda3 Autodock CESM Community Earth System Model, or CESM, is a fully-coupled, community, global climate model that provides state-of-the-art computer simulations of the Earth's past, present, and future climate states. DIVEMESH Gaussian GROMACS GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers. LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) a classical molecular dynamics code. MFIX Molpro Molpro is a complete system of ab initio programs for molecular electronic structure calculations, designed and maintained by H.-J. Werner and P. J. Knowles, and containing contributions from a number of other authors. As distinct from other commonly used quantum chemistry packages, the emphasis is on highly accurate computations, with extensive treatment of the electron correlation problem through the multiconfiguration-reference CI, coupled cluster and associated methods. OpenFOAM OpenFOAM is an open-source toolbox for computational fluid dynamics. OpenFOAM consists of generic tools to simulate complex physics for a variety of fields of interest, from fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics, electromagnetism and the pricing of financial options. The core technology of OpenFOAM is a flexible set of modules written in C++. These are used to build solvers and utilities to perform pre- and post-processing tasks ranging from simple data manipulation to visualisation and mesh processing. Quantum Espresso Quantum Espresso is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. REEF3D SIESTA (Spanish Initiative for Electronic Simulations with Thousands of Atoms) is a program to perform electronic structure calculations and ab initio molecular dynamics simulations of molecules and solids. Wavewatch Xbeach VASP A package for ab initio, quantum-mechanical, molecular dynamics simulations.","title":"Software Catalogue"},{"location":"softwares/","text":"Use Software \u00b6 To best serve the diverse needs of all our users, we use software modules to make multiple versions of popular software available. Modules allow you to swap between different applications and versions of those applications with relative ease. We also provide assistance for installing less commonly used packages. See our Applications & Software documentation for more details.","title":"Software"},{"location":"softwares/#use-software","text":"To best serve the diverse needs of all our users, we use software modules to make multiple versions of popular software available. Modules allow you to swap between different applications and versions of those applications with relative ease. We also provide assistance for installing less commonly used packages. See our Applications & Software documentation for more details.","title":"Use Software"},{"location":"storage/","text":"Storage \u00b6 About Madhava HPC Storage \u00b6 Since there are many users and large computations used to run, much more space is needed to store all user data compared to a personal computer. In Madhava HPC Cluster different types of storages are there. Like a desktop or laptop computer, individual cluster nodes often have local disk drives. Since this storage is local to a node, it is usually faster to access by the processes running on the node. On Madhava HPC Cluster these local drives are used for system softwares. Most of the data on a cluster is kept in separate storage units that have multiple hard drives. These units are called file servers. A file server is a computer with the primary purpose of providing a location to store data. Regular users do not login to file servers. On HPC clusters these file servers are connected to the same Infiniband switch that connects all nodes, providing relatively fast access to data from all cluster nodes. Every user on a cluster has a home directory. If you type \"pwd\" right after ssh-ing to a cluster, you should see /gpfs-home/ , where is your Login Id & home directories are accessed on any cluster node. Since there are multiple users on a cluster, to minimize one user's actions affecting other users, home directories have quotas. On HPC clusters listed on this site, one can not keep more than 500GB of data in their home directory. Users keep important data in the home directories. For optimal performance we recommend to keep file system less than 70% full. And finally cluster have separate scratch space named /gpfs-scratch/ that is mounted on all nodes. This storage is not backed up and is purged regularly. Users are requested to use this space as their SCRATCH directory instead of /tmp for smooth running of the program. Since many high computational jobs create scratch files of large size, using scratch to /tmp will lead to inapprpriate halting of the code and functioning of the cluster. If users couldn't find their directory in /gpfs-scratch, please contact CCMS Admin. Storage Policies \u00b6 Use /gpfs-home/ and /gpfs-scratch/ as your home and scratch directory. regularly backup your important files from /gpfs-scratch The quota for home and scratch is shown in table below. Directory Quota Home directory 204TB Scratch Directoty 70 TB User Home 500 Gb","title":"Storage"},{"location":"storage/#storage","text":"","title":"Storage"},{"location":"storage/#about-madhava-hpc-storage","text":"Since there are many users and large computations used to run, much more space is needed to store all user data compared to a personal computer. In Madhava HPC Cluster different types of storages are there. Like a desktop or laptop computer, individual cluster nodes often have local disk drives. Since this storage is local to a node, it is usually faster to access by the processes running on the node. On Madhava HPC Cluster these local drives are used for system softwares. Most of the data on a cluster is kept in separate storage units that have multiple hard drives. These units are called file servers. A file server is a computer with the primary purpose of providing a location to store data. Regular users do not login to file servers. On HPC clusters these file servers are connected to the same Infiniband switch that connects all nodes, providing relatively fast access to data from all cluster nodes. Every user on a cluster has a home directory. If you type \"pwd\" right after ssh-ing to a cluster, you should see /gpfs-home/ , where is your Login Id & home directories are accessed on any cluster node. Since there are multiple users on a cluster, to minimize one user's actions affecting other users, home directories have quotas. On HPC clusters listed on this site, one can not keep more than 500GB of data in their home directory. Users keep important data in the home directories. For optimal performance we recommend to keep file system less than 70% full. And finally cluster have separate scratch space named /gpfs-scratch/ that is mounted on all nodes. This storage is not backed up and is purged regularly. Users are requested to use this space as their SCRATCH directory instead of /tmp for smooth running of the program. Since many high computational jobs create scratch files of large size, using scratch to /tmp will lead to inapprpriate halting of the code and functioning of the cluster. If users couldn't find their directory in /gpfs-scratch, please contact CCMS Admin.","title":"About Madhava HPC Storage"},{"location":"storage/#storage-policies","text":"Use /gpfs-home/ and /gpfs-scratch/ as your home and scratch directory. regularly backup your important files from /gpfs-scratch The quota for home and scratch is shown in table below. Directory Quota Home directory 204TB Scratch Directoty 70 TB User Home 500 Gb","title":"Storage Policies"},{"location":"submit/","text":"SLURM Job Submission \u00b6 To submit a batch job for later execution, run the sbatch command followed by the path to the script file on a login node. $ sbatch script.sh submitted batch 2021 Upon successful submission of a job, a unique job ID ( i.e. 2021 in this example) is assigned by SLURM, which may be referred to for job management such as job status checking and cancellation. By default, SLURM directs both standard output and standard error during job execution to a single file, named slurm-%j.out and slurm-%A_%a.out for standalone and array jobs respectively. The default path may be override with --output=%x_%j.out and --error=%x_%j.err for path to standard output and standard error respectively. User may compose a path using any combination of replacement symbols (% followed by a letter). Replacement symbols \u00b6 Replacement Symbol Description %A Job array\u2019s master job allocation number %a Job array ID (index) number %J JobID.stepid of the running job (e.g. \u201c128.0\u201d) %j JobID of the running job %x Job name Besides putting SLURM directives inside a script file, they may be supplied to job submission commands like sbatch, srun and salloc as command-line arguments, which will take precedence over any specified values inside a script file. e.g. Request 1 compute node with 32 cores per task and 4GB RAM, where any specified value for -N, -c, and --mem inside script.cmd are ignored. $ sbatch -N1 -c32 --mem=4G script.sh","title":"Slurm Job Submission"},{"location":"submit/#slurm-job-submission","text":"To submit a batch job for later execution, run the sbatch command followed by the path to the script file on a login node. $ sbatch script.sh submitted batch 2021 Upon successful submission of a job, a unique job ID ( i.e. 2021 in this example) is assigned by SLURM, which may be referred to for job management such as job status checking and cancellation. By default, SLURM directs both standard output and standard error during job execution to a single file, named slurm-%j.out and slurm-%A_%a.out for standalone and array jobs respectively. The default path may be override with --output=%x_%j.out and --error=%x_%j.err for path to standard output and standard error respectively. User may compose a path using any combination of replacement symbols (% followed by a letter).","title":"SLURM Job Submission"},{"location":"submit/#replacement-symbols","text":"Replacement Symbol Description %A Job array\u2019s master job allocation number %a Job array ID (index) number %J JobID.stepid of the running job (e.g. \u201c128.0\u201d) %j JobID of the running job %x Job name Besides putting SLURM directives inside a script file, they may be supplied to job submission commands like sbatch, srun and salloc as command-line arguments, which will take precedence over any specified values inside a script file. e.g. Request 1 compute node with 32 cores per task and 4GB RAM, where any specified value for -N, -c, and --mem inside script.cmd are ignored. $ sbatch -N1 -c32 --mem=4G script.sh","title":"Replacement symbols"},{"location":"system_configuration/","text":"System Hardware & Configuration \u00b6 Total number of nodes: 36 (1 + 31 + 2 + 2) Master/Login/Service nodes: 1 CPU nodes: 31 GPU accelerated nodes: 2 Storage nodes: 2 Master/Login/Service Node:1 \u00b6 Madhava HPC cluster is an aggregation of a large number of computers connected through networks. The basic purpose of the master node is to manage and monitor each of the constituent component of Madhava HPC from a system\u2019s perspective. This involves operations like monitoring the health of the components, the load on the components, the utilization of various sub-components of the computers in Madhava HPC. This also works as a login node which used for administrative tasks such as editing, writing scripts, transferring files, managing your jobs and the like. You will always get connected to one of the login nodes. From the login nodes you can get connected to a compute node and execute and interactive job or submit batch jobs through the batch system (SLURM) to run your jobs on compute nodes. For ALL users Madhava HPC Cluster login nodes are the entry points and hence are shared. This node also works as a service node to provide Job Scheduling Services and other services to the cluster Master/ Login/service Nodes : 1 Model Lenovo ThinkSystem SR650 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 64 cores RAM 192 GB HDD 2 TB CPU Nodes:31 \u00b6 CPU nodes are indeed the work horses of Madhava HPC. All the CPU intensive activities are carried on these nodes. Users can access these nodes from the login node to run interactive or batch jobs. by users in the aforementioned way. CPU Only Nodes : 31 Model Lenovo ThinkSystem SR630 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB GPU Nodes:2 \u00b6 GPU compute nodes are the nodes that have CPU cores along with accelerators cards. For some applications GPUs get markedly high performance. For exploiting these, one has to make use of special libraries which map computations on the Graphical Processing Units (Typically one has to make use of CUDA or OpencCL). CPU Only Nodes : 31 Model Lenovo ThinkSystem SR650 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB GPU 2* Tesla V100-PCIE-32GB per node GPU cores per node 2* 5120 GPU Tensor Cores 2* 640 Storage/ IO nodes:2 \u00b6 Providing the storage service to head and compute nodes using GPFS Storage/ IO nodes:2 Model Lenovo ThinkSystem SR630 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB Storage Array :2 \u00b6 It's a backend to the IO nodes which is providing storage service to head and compute nodes Storage/ IO nodes:2 Model ThinkSystem DE6000H 2 nos of DE Controller with 16 GB, 60 Chasis. Home Space 204 TB Scratch Space 60 TB","title":"System Configuration"},{"location":"system_configuration/#system-hardware-configuration","text":"Total number of nodes: 36 (1 + 31 + 2 + 2) Master/Login/Service nodes: 1 CPU nodes: 31 GPU accelerated nodes: 2 Storage nodes: 2","title":"System Hardware &amp; Configuration"},{"location":"system_configuration/#masterloginservice-node1","text":"Madhava HPC cluster is an aggregation of a large number of computers connected through networks. The basic purpose of the master node is to manage and monitor each of the constituent component of Madhava HPC from a system\u2019s perspective. This involves operations like monitoring the health of the components, the load on the components, the utilization of various sub-components of the computers in Madhava HPC. This also works as a login node which used for administrative tasks such as editing, writing scripts, transferring files, managing your jobs and the like. You will always get connected to one of the login nodes. From the login nodes you can get connected to a compute node and execute and interactive job or submit batch jobs through the batch system (SLURM) to run your jobs on compute nodes. For ALL users Madhava HPC Cluster login nodes are the entry points and hence are shared. This node also works as a service node to provide Job Scheduling Services and other services to the cluster Master/ Login/service Nodes : 1 Model Lenovo ThinkSystem SR650 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 64 cores RAM 192 GB HDD 2 TB","title":"Master/Login/Service Node:1"},{"location":"system_configuration/#cpu-nodes31","text":"CPU nodes are indeed the work horses of Madhava HPC. All the CPU intensive activities are carried on these nodes. Users can access these nodes from the login node to run interactive or batch jobs. by users in the aforementioned way. CPU Only Nodes : 31 Model Lenovo ThinkSystem SR630 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB","title":"CPU Nodes:31"},{"location":"system_configuration/#gpu-nodes2","text":"GPU compute nodes are the nodes that have CPU cores along with accelerators cards. For some applications GPUs get markedly high performance. For exploiting these, one has to make use of special libraries which map computations on the Graphical Processing Units (Typically one has to make use of CUDA or OpencCL). CPU Only Nodes : 31 Model Lenovo ThinkSystem SR650 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB GPU 2* Tesla V100-PCIE-32GB per node GPU cores per node 2* 5120 GPU Tensor Cores 2* 640","title":"GPU Nodes:2"},{"location":"system_configuration/#storage-io-nodes2","text":"Providing the storage service to head and compute nodes using GPFS Storage/ IO nodes:2 Model Lenovo ThinkSystem SR630 Processor 2 nos of Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. Cores 40 cores RAM 192 GB HDD 1 TB","title":"Storage/ IO nodes:2"},{"location":"system_configuration/#storage-array-2","text":"It's a backend to the IO nodes which is providing storage service to head and compute nodes Storage/ IO nodes:2 Model ThinkSystem DE6000H 2 nos of DE Controller with 16 GB, 60 Chasis. Home Space 204 TB Scratch Space 60 TB","title":"Storage Array :2"},{"location":"transfer/","text":"Command-Line Transfer Tools \u00b6 scp and rsync (macOS/Linux/Linux on Windows) \u00b6 Linux and macOS users can use scp or rsync. Use the ipaddress of the cluster (Recieved on mail on account creation) to transfer files. These transfers must be initiated from your local machine. scp and sftp are both used from a Terminal window. The basic syntax of scp is scp [from] [to] The from and to can each be a filename or a directory/folder on the computer you are typing the command on or a remote host. Example: Transfer a File from Your Computer to a Cluster \u00b6 Using the example netid abc123, following is run on your computer's local terminal. scp myfile.txt abc123@[ipaadress]:/gpfs-home/abc123/test In this example, myfile.txt is copied to the directory /gpfs-home/abc123/test: on Grace. This example assumes that myfile.txt is in your current directory. You may also specify the full path of myfile.txt. scp /home/xyz/myfile.txt abc123@[ipaadress]:/gpfs-home/abc123/test Example: Transfer a Directory to a Cluster \u00b6 scp -r mydirectory abc123@[ipaadress]:/gpfs-home/abc123/test In this example, the contents of mydirectory are transferred. The -r indicates that the copy is recursive. Example: Transfer Files from the Cluster to Your Computer Assuming you would like the files copied to your current directory: scp abc123@[ipaadress]:/gpfs-home/abc123/myfile.txt . Note that . represents your current working directory. To specify the destination, simply replace the . with the full path: scp abc123@[ipaadress]:/gpfs-home/abc123/myfile.txt /path/myfolder","title":"Transfering Files In & Out"},{"location":"transfer/#command-line-transfer-tools","text":"","title":"Command-Line Transfer Tools"},{"location":"transfer/#scp-and-rsync-macoslinuxlinux-on-windows","text":"Linux and macOS users can use scp or rsync. Use the ipaddress of the cluster (Recieved on mail on account creation) to transfer files. These transfers must be initiated from your local machine. scp and sftp are both used from a Terminal window. The basic syntax of scp is scp [from] [to] The from and to can each be a filename or a directory/folder on the computer you are typing the command on or a remote host.","title":"scp and rsync (macOS/Linux/Linux on Windows)"},{"location":"transfer/#example-transfer-a-file-from-your-computer-to-a-cluster","text":"Using the example netid abc123, following is run on your computer's local terminal. scp myfile.txt abc123@[ipaadress]:/gpfs-home/abc123/test In this example, myfile.txt is copied to the directory /gpfs-home/abc123/test: on Grace. This example assumes that myfile.txt is in your current directory. You may also specify the full path of myfile.txt. scp /home/xyz/myfile.txt abc123@[ipaadress]:/gpfs-home/abc123/test","title":"Example: Transfer a File from Your Computer to a Cluster"},{"location":"transfer/#example-transfer-a-directory-to-a-cluster","text":"scp -r mydirectory abc123@[ipaadress]:/gpfs-home/abc123/test In this example, the contents of mydirectory are transferred. The -r indicates that the copy is recursive. Example: Transfer Files from the Cluster to Your Computer Assuming you would like the files copied to your current directory: scp abc123@[ipaadress]:/gpfs-home/abc123/myfile.txt . Note that . represents your current working directory. To specify the destination, simply replace the . with the full path: scp abc123@[ipaadress]:/gpfs-home/abc123/myfile.txt /path/myfolder","title":"Example: Transfer a Directory to a Cluster"}]}